{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Tree-based Models in Python](https://www.datacamp.com/completed/statement-of-accomplishment/course/139ce5b390a8d8c6aff4bf1fc2d8eeb099c2d5c8)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adamelliotfields/datacamp/blob/main/notebooks/courses/tree_models_in_python/notebook.ipynb)\n",
    "[![Render nbviewer](https://raw.githubusercontent.com/jupyter/design/main/logos/Badges/nbviewer_badge.svg)](https://nbviewer.org/github/adamelliotfields/datacamp/blob/main/notebooks/courses/tree_models_in_python/notebook.ipynb)\n",
    "\n",
    "**Contents**\n",
    "- [Data](#Data)\n",
    "- [Classification and Regression Trees](#Classification-and-Regression-Trees)\n",
    "- [Bias-Variance Tradeoff](#Bias-Variance-Tradeoff)\n",
    "- [Parallel Ensembles](#Parallel-Ensembles)\n",
    "- [Boosting](#Boosting)\n",
    "- [Hyperparameter Tuning](#Hyperparameter-Tuning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    BaggingClassifier,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings(\"ignore\", category=UserWarning)\n",
    "filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FitFailedWarning,\n",
    "    module=\"sklearn.model_selection\",\n",
    ")  # final exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto MPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>mpg</th>\n",
       "      <th>origin_us</th>\n",
       "      <th>origin_europe</th>\n",
       "      <th>origin_asia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4</td>\n",
       "      <td>96.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2189</td>\n",
       "      <td>18.0</td>\n",
       "      <td>72</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>2795</td>\n",
       "      <td>15.7</td>\n",
       "      <td>78</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1800</td>\n",
       "      <td>16.4</td>\n",
       "      <td>78</td>\n",
       "      <td>36.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>20.5</td>\n",
       "      <td>71</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cylinders  displacement  horsepower  weight  acceleration  model_year  \\\n",
       "79           4          96.0        69.0    2189          18.0          72   \n",
       "276          4         121.0       115.0    2795          15.7          78   \n",
       "248          4          91.0        60.0    1800          16.4          78   \n",
       "56           4          91.0        70.0    1955          20.5          71   \n",
       "393          4         140.0        86.0    2790          15.6          82   \n",
       "\n",
       "      mpg  origin_us  origin_europe  origin_asia  \n",
       "79   26.0          0              1            0  \n",
       "276  21.6          0              1            0  \n",
       "248  36.1          0              0            1  \n",
       "56   26.0          1              0            0  \n",
       "393  27.0          1              0            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://archive.ics.uci.edu/dataset/9/auto+mpg\n",
    "auto_mpg = fetch_ucirepo(id=9)\n",
    "auto_df = auto_mpg.data.original\n",
    "\n",
    "# drop `car_name` column\n",
    "auto_df = auto_df.drop(\"car_name\", axis=1)\n",
    "\n",
    "# drop missing `horsepower` rows\n",
    "auto_df = auto_df.dropna(subset=[\"horsepower\"])\n",
    "\n",
    "# one-hot encode `origin` column\n",
    "auto_df = pd.get_dummies(\n",
    "    auto_df,\n",
    "    columns=[\"origin\"],\n",
    "    dtype=\"int8\",\n",
    ")\n",
    "auto_df = auto_df.rename(\n",
    "    columns={\n",
    "        \"origin_1\": \"origin_us\",\n",
    "        \"origin_2\": \"origin_europe\",\n",
    "        \"origin_3\": \"origin_asia\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# display\n",
    "display(auto_df.sample(5, random_state=42))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breast Cancer Wisconsin (Diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius1</th>\n",
       "      <th>texture1</th>\n",
       "      <th>perimeter1</th>\n",
       "      <th>area1</th>\n",
       "      <th>smoothness1</th>\n",
       "      <th>compactness1</th>\n",
       "      <th>concavity1</th>\n",
       "      <th>concave_points1</th>\n",
       "      <th>symmetry1</th>\n",
       "      <th>fractal_dimension1</th>\n",
       "      <th>...</th>\n",
       "      <th>texture3</th>\n",
       "      <th>perimeter3</th>\n",
       "      <th>area3</th>\n",
       "      <th>smoothness3</th>\n",
       "      <th>compactness3</th>\n",
       "      <th>concavity3</th>\n",
       "      <th>concave_points3</th>\n",
       "      <th>symmetry3</th>\n",
       "      <th>fractal_dimension3</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>12.47</td>\n",
       "      <td>18.60</td>\n",
       "      <td>81.09</td>\n",
       "      <td>481.9</td>\n",
       "      <td>0.09965</td>\n",
       "      <td>0.1058</td>\n",
       "      <td>0.08005</td>\n",
       "      <td>0.03821</td>\n",
       "      <td>0.1925</td>\n",
       "      <td>0.06373</td>\n",
       "      <td>...</td>\n",
       "      <td>24.64</td>\n",
       "      <td>96.05</td>\n",
       "      <td>677.9</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>0.2378</td>\n",
       "      <td>0.2671</td>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.3014</td>\n",
       "      <td>0.08750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>18.94</td>\n",
       "      <td>21.31</td>\n",
       "      <td>123.60</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>0.09009</td>\n",
       "      <td>0.1029</td>\n",
       "      <td>0.10800</td>\n",
       "      <td>0.07951</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.05461</td>\n",
       "      <td>...</td>\n",
       "      <td>26.58</td>\n",
       "      <td>165.90</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>0.1193</td>\n",
       "      <td>0.2336</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.17890</td>\n",
       "      <td>0.2551</td>\n",
       "      <td>0.06589</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.1223</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>0.1931</td>\n",
       "      <td>0.05796</td>\n",
       "      <td>...</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.1546</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>12.40</td>\n",
       "      <td>17.68</td>\n",
       "      <td>81.47</td>\n",
       "      <td>467.8</td>\n",
       "      <td>0.10540</td>\n",
       "      <td>0.1316</td>\n",
       "      <td>0.07741</td>\n",
       "      <td>0.02799</td>\n",
       "      <td>0.1811</td>\n",
       "      <td>0.07102</td>\n",
       "      <td>...</td>\n",
       "      <td>22.91</td>\n",
       "      <td>89.61</td>\n",
       "      <td>515.8</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.2629</td>\n",
       "      <td>0.2403</td>\n",
       "      <td>0.07370</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>0.09359</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>11.54</td>\n",
       "      <td>14.44</td>\n",
       "      <td>74.65</td>\n",
       "      <td>402.9</td>\n",
       "      <td>0.09984</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.06737</td>\n",
       "      <td>0.02594</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>0.06782</td>\n",
       "      <td>...</td>\n",
       "      <td>19.68</td>\n",
       "      <td>78.78</td>\n",
       "      <td>457.8</td>\n",
       "      <td>0.1345</td>\n",
       "      <td>0.2118</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>0.06918</td>\n",
       "      <td>0.2329</td>\n",
       "      <td>0.08134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius1  texture1  perimeter1   area1  smoothness1  compactness1  \\\n",
       "204    12.47     18.60       81.09   481.9      0.09965        0.1058   \n",
       "70     18.94     21.31      123.60  1130.0      0.09009        0.1029   \n",
       "131    15.46     19.48      101.70   748.9      0.10920        0.1223   \n",
       "431    12.40     17.68       81.47   467.8      0.10540        0.1316   \n",
       "540    11.54     14.44       74.65   402.9      0.09984        0.1120   \n",
       "\n",
       "     concavity1  concave_points1  symmetry1  fractal_dimension1  ...  \\\n",
       "204     0.08005          0.03821     0.1925             0.06373  ...   \n",
       "70      0.10800          0.07951     0.1582             0.05461  ...   \n",
       "131     0.14660          0.08087     0.1931             0.05796  ...   \n",
       "431     0.07741          0.02799     0.1811             0.07102  ...   \n",
       "540     0.06737          0.02594     0.1818             0.06782  ...   \n",
       "\n",
       "     texture3  perimeter3   area3  smoothness3  compactness3  concavity3  \\\n",
       "204     24.64       96.05   677.9       0.1426        0.2378      0.2671   \n",
       "70      26.58      165.90  1866.0       0.1193        0.2336      0.2687   \n",
       "131     26.00      124.90  1156.0       0.1546        0.2394      0.3791   \n",
       "431     22.91       89.61   515.8       0.1450        0.2629      0.2403   \n",
       "540     19.68       78.78   457.8       0.1345        0.2118      0.1797   \n",
       "\n",
       "     concave_points3  symmetry3  fractal_dimension3  Diagnosis  \n",
       "204          0.10150     0.3014             0.08750          0  \n",
       "70           0.17890     0.2551             0.06589          1  \n",
       "131          0.15140     0.2837             0.08019          1  \n",
       "431          0.07370     0.2556             0.09359          0  \n",
       "540          0.06918     0.2329             0.08134          0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic\n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
    "cancer_df = breast_cancer_wisconsin_diagnostic.data.original\n",
    "\n",
    "# drop `ID` column\n",
    "cancer_df = cancer_df.drop(\"ID\", axis=1)\n",
    "\n",
    "# encode `Diagnosis` column (B=benign, M=malignant)\n",
    "cancer_df[\"Diagnosis\"] = cancer_df[\"Diagnosis\"].map({\"B\": 0, \"M\": 1})\n",
    "\n",
    "# display\n",
    "display(cancer_df.sample(5, random_state=42))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ILPD (Indian Liver Patient Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>TB</th>\n",
       "      <th>DB</th>\n",
       "      <th>Alkphos</th>\n",
       "      <th>Sgpt</th>\n",
       "      <th>Sgot</th>\n",
       "      <th>TP</th>\n",
       "      <th>ALB</th>\n",
       "      <th>A/G Ratio</th>\n",
       "      <th>Male</th>\n",
       "      <th>Patient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>-1.591632</td>\n",
       "      <td>-0.306051</td>\n",
       "      <td>-0.244506</td>\n",
       "      <td>-0.463793</td>\n",
       "      <td>-0.371107</td>\n",
       "      <td>-0.290680</td>\n",
       "      <td>1.398600</td>\n",
       "      <td>1.834526</td>\n",
       "      <td>1.109099</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-2.024373</td>\n",
       "      <td>-0.370523</td>\n",
       "      <td>-0.458327</td>\n",
       "      <td>1.765025</td>\n",
       "      <td>0.418091</td>\n",
       "      <td>-0.006619</td>\n",
       "      <td>0.660946</td>\n",
       "      <td>0.702217</td>\n",
       "      <td>0.166351</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.942997</td>\n",
       "      <td>0.387029</td>\n",
       "      <td>0.468230</td>\n",
       "      <td>-0.315480</td>\n",
       "      <td>1.815630</td>\n",
       "      <td>2.563784</td>\n",
       "      <td>0.753153</td>\n",
       "      <td>0.073157</td>\n",
       "      <td>-0.524997</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>-0.169767</td>\n",
       "      <td>-0.451114</td>\n",
       "      <td>-0.493964</td>\n",
       "      <td>-0.529710</td>\n",
       "      <td>0.407130</td>\n",
       "      <td>-0.006619</td>\n",
       "      <td>1.490806</td>\n",
       "      <td>1.079653</td>\n",
       "      <td>-0.147898</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>-0.293407</td>\n",
       "      <td>1.805424</td>\n",
       "      <td>1.751155</td>\n",
       "      <td>0.277773</td>\n",
       "      <td>-0.168327</td>\n",
       "      <td>-0.120936</td>\n",
       "      <td>-0.722154</td>\n",
       "      <td>-1.310776</td>\n",
       "      <td>-1.404895</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age        TB        DB   Alkphos      Sgpt      Sgot        TP  \\\n",
       "355 -1.591632 -0.306051 -0.244506 -0.463793 -0.371107 -0.290680  1.398600   \n",
       "407 -2.024373 -0.370523 -0.458327  1.765025  0.418091 -0.006619  0.660946   \n",
       "90   0.942997  0.387029  0.468230 -0.315480  1.815630  2.563784  0.753153   \n",
       "402 -0.169767 -0.451114 -0.493964 -0.529710  0.407130 -0.006619  1.490806   \n",
       "268 -0.293407  1.805424  1.751155  0.277773 -0.168327 -0.120936 -0.722154   \n",
       "\n",
       "          ALB  A/G Ratio  Male  Patient  \n",
       "355  1.834526   1.109099     1        0  \n",
       "407  0.702217   0.166351     1        1  \n",
       "90   0.073157  -0.524997     1        1  \n",
       "402  1.079653  -0.147898     0        1  \n",
       "268 -1.310776  -1.404895     1        1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://archive.ics.uci.edu/dataset/225/ilpd+indian+liver+patient+dataset\n",
    "indian_liver_patient = fetch_ucirepo(id=225)\n",
    "liver_df = indian_liver_patient.data.original\n",
    "liver_cat_cols = [\"Male\", \"Patient\"]\n",
    "liver_num_cols = [\n",
    "    \"Age\",\n",
    "    \"TB\",\n",
    "    \"DB\",\n",
    "    \"Alkphos\",\n",
    "    \"Sgpt\",\n",
    "    \"Sgot\",\n",
    "    \"TP\",\n",
    "    \"ALB\",\n",
    "    \"A/G Ratio\",\n",
    "]\n",
    "\n",
    "# encode `Gender` and `Selector` columns\n",
    "liver_df[\"Male\"] = liver_df[\"Gender\"].map({\"Female\": 0, \"Male\": 1})\n",
    "liver_df[\"Patient\"] = liver_df[\"Selector\"].map({2: 0, 1: 1})\n",
    "liver_df = liver_df.drop(columns=[\"Gender\", \"Selector\"], axis=1)\n",
    "\n",
    "# impute missing `A/G Ratio` values\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "liver_df[\"A/G Ratio\"] = imputer.fit_transform(liver_df[[\"A/G Ratio\"]])\n",
    "\n",
    "# scale every column except `Male` and `Patient`\n",
    "scaler = StandardScaler()\n",
    "liver_df[liver_num_cols] = scaler.fit_transform(liver_df[liver_num_cols])\n",
    "\n",
    "# display\n",
    "display(liver_df.sample(5, random_state=42))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bike Sharing Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>instant</th>\n",
       "      <th>mnth</th>\n",
       "      <th>yr</th>\n",
       "      <th>Clear to partly cloudy</th>\n",
       "      <th>Light Precipitation</th>\n",
       "      <th>Misty</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>14322</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>13903</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.2836</td>\n",
       "      <td>13443</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>13564</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>13437</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hr  holiday  workingday  temp   hum  windspeed  instant  mnth  yr  \\\n",
       "1318  22        0           1  0.70  0.61     0.0000    14322     8   1   \n",
       "899   11        0           1  0.76  0.66     0.0896    13903     8   1   \n",
       "439    7        0           1  0.74  0.58     0.2836    13443     7   1   \n",
       "560    8        0           1  0.74  0.70     0.1940    13564     7   1   \n",
       "433    1        0           1  0.74  0.66     0.0896    13437     7   1   \n",
       "\n",
       "      Clear to partly cloudy  Light Precipitation  Misty  cnt  \n",
       "1318                       0                    0      1  251  \n",
       "899                        0                    0      1  214  \n",
       "439                        1                    0      0  473  \n",
       "560                        1                    0      0  743  \n",
       "433                        1                    0      0   25  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://www.kaggle.com/c/bike-sharing-demand\n",
    "bikes_df = pd.read_csv(\"bike_sharing_demand.csv\")\n",
    "display(bikes_df.sample(5, random_state=42))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification and Regression Trees\n",
    "\n",
    "_Classification and Regression Trees_ (CART) are a set of supervised learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees\n",
    "\n",
    "A _decision tree_ is a flowchat-like structure where each internal node represents a \"test\" on a feature (e.g., heads or tails).\n",
    "\n",
    "The root node at the top of the tree represents the entire dataset. The choice of which feature to test is determined by criteria like _information gain_, _Gini impurity_, and _variance reduction_.\n",
    "\n",
    "The tree is grown by partitioning the data into subsets that are as homogenous as possible. This partitioning continues until a stopping criterion is reached, like maximum tree depth, minimum samples per leaf, minimum samples required to split, etc.\n",
    "\n",
    "**Links**\n",
    "* <https://en.wikipedia.org/wiki/Decision_tree_learning>\n",
    "* <https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html>\n",
    "* <https://developers.google.com/machine-learning/decision-forests/decision-trees>\n",
    "* <https://blog.paperspace.com/decision-trees>\n",
    "\n",
    "**Videos**\n",
    "- [@statquest: Decision and Classification Trees, Clearly Explained!!!](https://www.youtube.com/watch?v=_L39rN6gz7Y)\n",
    "- [@statquest: Regression Trees, Clearly Explained!!!](https://www.youtube.com/watch?v=g9c66TUylZ4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification\n",
    "\n",
    "A _classification tree_ is a decision tree where the target variable is categorical. The leafs of the tree represent the class labels and the branches represent the conjunctions of features that lead to those class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "# train/test split\n",
    "X = cancer_df.drop(\"Diagnosis\", axis=1).values\n",
    "y = cancer_df[\"Diagnosis\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# fit and predict\n",
    "dt = DecisionTreeClassifier(max_depth=6, random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Decision Tree Accuracy: {acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression\n",
    "\n",
    "A _regression tree_ is a decision tree where the target variable is continuous. Unlike in a classification tree, the prediction for a regression tree is the average of the observations in the leaf that the observation you're trying to predict belongs to. Like a classification tree, the depth is limited by a stopping criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE: 3.26\n",
      "Regression Tree RMSE: 3.97\n"
     ]
    }
   ],
   "source": [
    "# train/test split\n",
    "X = auto_df.drop(\"mpg\", axis=1).values\n",
    "y = auto_df[\"mpg\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# fit decision tree regressor\n",
    "dt = DecisionTreeRegressor(\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=0.13,\n",
    "    random_state=42,\n",
    ")\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "mse_dt = mean_squared_error(y_test, y_pred)\n",
    "rmse_dt = mse_dt ** (1 / 2)\n",
    "\n",
    "# fit linear regressor\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "rmse_lr = mse_lr ** (1 / 2)\n",
    "\n",
    "print(\"Linear Regression RMSE: {:.2f}\".format(rmse_lr))  # 3.26\n",
    "print(\"Regression Tree RMSE: {:.2f}\".format(rmse_dt))  # 3.97\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-Variance Tradeoff\n",
    "\n",
    "The _Bias-Variance Tradeoff_ is a fundamental concept in machine learning that describes the balance between the two sources of error in a model: _bias_ and _variance_.\n",
    "\n",
    "Bias is introduced when a model makes overly simplistic assumptions about the data. High bias leads to missing relationships between features and the target output, which is known as _underfitting_.\n",
    "\n",
    "Variance is when there is too much complexity in the learning algorithm. High variance leads to the model learning noise from the training data, which then leads to poor predictions on data it hasn't seen before. This means the model is not able to \"generalize\" well, which is known as _overfitting_.\n",
    "\n",
    "Linear models, due to their simplicity and the assumption of a linear relationship between the features and the target, typically exhibit high bias and low variance. This simplicity makes them less sensitive to noise, hence the low variance.\n",
    "\n",
    "Tree-based models often have low bias and high variance. They can capture more complex patterns and interactions between variables, making them more adaptable to the data (low bias). However, this also makes them more sensitive to noise (high variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE: 4.68\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "dt = DecisionTreeRegressor(\n",
    "    max_depth=4,\n",
    "    min_samples_leaf=0.26,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# 10-folds cross-validation negative MSE\n",
    "MSE_CV_scores = -cross_val_score(\n",
    "    dt,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=10,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# 10-folds CV RMSE\n",
    "RMSE_CV = (MSE_CV_scores.mean()) ** (1 / 2)\n",
    "print(f\"CV RMSE: {RMSE_CV:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 4.29\n"
     ]
    }
   ],
   "source": [
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# predict training set labels\n",
    "y_pred = dt.predict(X_train)\n",
    "\n",
    "# evaluate training set RMSE\n",
    "rmse = mean_squared_error(y_train, y_pred) ** (1 / 2)\n",
    "print(f\"Train RMSE: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Learning\n",
    "\n",
    "_Ensemble learning_ is a technique where multiple models, often called \"weak learners\", are trained to solve the same problem. The predictions of the weak learners are then combined to produce a single prediction.\n",
    "\n",
    "The idea is that multiple weak learners can together form more reliable predictions than any individual model.\n",
    "\n",
    "Ensemble algorithms are known as _meta-models_ because they act as wrappers around other models. For example, a _Voting Classifier_ is not a model itself. The models it wraps are known as _estimators_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting Classifiers\n",
    "\n",
    "In voting ensembles, multiple models are trained separately and their predictions are combined by taking the majority vote (for classification) or average (for regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.76\n",
      "K Nearest Neighbours Accuracy: 0.70\n",
      "Classification Tree Accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "X = liver_df.drop(\"Patient\", axis=1).values\n",
    "y = liver_df[\"Patient\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=27)\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=0.13, random_state=42)\n",
    "classifiers = [\n",
    "    (\"Logistic Regression\", lr),\n",
    "    (\"K Nearest Neighbours\", knn),\n",
    "    (\"Classification Tree\", dt),\n",
    "]\n",
    "\n",
    "for clf_name, clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{clf_name} Accuracy: {acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "vc = VotingClassifier(estimators=classifiers)\n",
    "vc.fit(X_train, y_train)\n",
    "y_pred = vc.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Voting Classifier Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Ensembles\n",
    "\n",
    "_Parallel_ ensembles help with errors due to variance, that is, if your model is overfitting. They are parallel in that each learner is built independently of the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "\n",
    "_Bagging_ means _bootstrap aggregating_. Bootstrapping is the process of taking repeated samples from a dataset (with replacement) and then training a separate model on each sample. The models are then aggregated by averaging the predictions of each model.\n",
    "\n",
    "Bootstrapping introduces diversity into the training process, which reduces overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier Accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "bc = BaggingClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "bc.fit(X_train, y_train)\n",
    "y_pred = bc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"BaggingClassifier Accuracy: {acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier OOB Score: 0.68\n"
     ]
    }
   ],
   "source": [
    "bc = BaggingClassifier(\n",
    "    n_estimators=50,\n",
    "    oob_score=True,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "bc.fit(X_train, y_train)\n",
    "y_pred = bc.predict(X_test)\n",
    "oob = bc.oob_score_\n",
    "print(f\"BaggingClassifier OOB Score: {oob:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests\n",
    "\n",
    "A _forest_ is an ensemble of _trees_. A Random Forest in particular is an ensemble of Decision Trees where each tree has been trained with bagging as well as the _random subspace method_. This technique, also known as _feature bagging_, is where each node (including root) is split on a random subset of features. This randomization introduces further diversity into the ensemble on top of bagging, which makes Random Forests even more resilient to overfitting.\n",
    "\n",
    "**Links**\n",
    "- <https://en.wikipedia.org/wiki/Random_forest>\n",
    "- <https://developers.google.com/machine-learning/decision-forests/random-forests>\n",
    "\n",
    "**Videos**\n",
    "- [@statquest: Random Forests Part 1 - Building, Using and Evaluating](https://www.youtube.com/watch?v=J4Wdy0Wc_xQ)\n",
    "- [@statquest: Random Forests Part 2 - Missing data and clustering](https://www.youtube.com/watch?v=sQ870aTKqiM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor RMSE: 57.44\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    n_estimators=25,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "X = bikes_df.drop(\"cnt\", axis=1).values\n",
    "y = bikes_df[\"cnt\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "rmse_test = mean_squared_error(y_test, y_pred) ** (1 / 2)\n",
    "print(f\"RandomForestRegressor RMSE: {rmse_test:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = pd.Series(\n",
    "    data=rf.feature_importances_,\n",
    "    index=bikes_df.drop(\"cnt\", axis=1).columns,\n",
    ")\n",
    "importances_sorted = importances.sort_values()\n",
    "importances_sorted.plot(kind=\"barh\", color=\"lightgreen\")\n",
    "plt.title(\"Features Importances\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "\n",
    "While bagging and random forests train multiple learners in parallel, _boosting_ trains multiple learners in sequence. Instead of aggregating the predictions of many weak learners, boosting trains a weak learner to be a strong learner. This is done by training each learner to correct the mistakes of the previous learner.\n",
    "\n",
    "Boosting algorithms introduce the `learning_rate` hyperparameter, which controls how much each learner corrects the mistakes of the previous learner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Boosting\n",
    "\n",
    "_Adaptive boosting_ or AdaBoost sequentially trains a series of learners. Each learner is trained on a modified version of the training set where the weights of misclassified observations are increased. This means that each learner focuses more on the observations that the previous learner got wrong. Throughout training, each learner is assigned a weight based on its accuracy. The final prediction is a weighted sum of the predictions of each learner (the ensemble).\n",
    "\n",
    "**Links**\n",
    "- <https://en.wikipedia.org/wiki/AdaBoost>\n",
    "- <https://blog.paperspace.com/adaboost-optimizer>\n",
    "\n",
    "**Videos**\n",
    "- [@statquest: AdaBoost, Clearly Explained](https://www.youtube.com/watch?v=LsK-xG1cLYA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.69\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(learning_rate=1, n_estimators=180, random_state=1)\n",
    "\n",
    "X = liver_df.drop(\"Patient\", axis=1).values\n",
    "y = liver_df[\"Patient\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "ada.fit(X_train, y_train)\n",
    "y_pred_proba = ada.predict_proba(X_test)[:, 1]\n",
    "\n",
    "ada_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"ROC AUC score: {ada_roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting\n",
    "\n",
    "Learners in a _gradient boosting_ ensemble are trained sequentially, like in AdaBoost. However, instead of modifying the weights of the training set, gradient boosting uses _gradient descent_ to minimize the _loss function_ of the model.\n",
    "\n",
    "The loss function essentially measures how wrong a model's predictions are compared to the actual values. The algorithm starts with simple initial predictions - like the average of the target values - then it calculates the residuals (the difference between the actual values and the predictions). The subsequent learners are then trained to predict the residuals of the previous learner. By making closer predictions to the actual values, the residuals are minimized (made closer to zero) and thus so is the loss function.\n",
    "\n",
    "When making predictions, the output of the ensemble is the sum of the initial predictions and the predictions of each learner weighted by the learning rate. If you have a low learning rate, then the ensemble will have to train more learners to make accurate predictions.\n",
    "\n",
    "For classification problems, the final prediction is the sum of the initial predictions and the predictions of each learner weighted by the learning rate. The final prediction is then converted to a probability using the _sigmoid function_ for binary classification or the _softmax function_ for multiclass classification.\n",
    "\n",
    "For regression problems, the final prediction is the sum of the initial predictions and the predictions of each learner weighted by the learning rate (no activation function is used).\n",
    "\n",
    "**Links**\n",
    "- <https://en.wikipedia.org/wiki/Gradient_boosting>\n",
    "\n",
    "**Videos**\n",
    "- [@statquest: Gradient Boost Part 1 (of 4): Regression Main Ideas](https://www.youtube.com/watch?v=3CC4N4z3GJc)\n",
    "- [@statquest: Gradient Boost Part 2 (of 4): Regression Details](https://www.youtube.com/watch?v=2xudPOBz-vs)\n",
    "- [@statquest: Gradient Boost Part 3 (of 4): Classification](https://www.youtube.com/watch?v=jxuNLH5dXCs)\n",
    "- [@statquest: Gradient Boost Part 4 (of 4): Classification Details](https://www.youtube.com/watch?v=StWY5QWMXCw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor RMSE: 51.56\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingRegressor(\n",
    "    learning_rate=0.1,\n",
    "    max_depth=4,\n",
    "    n_estimators=200,\n",
    "    random_state=2,\n",
    ")\n",
    "\n",
    "X = bikes_df.drop(\"cnt\", axis=1).values\n",
    "y = bikes_df[\"cnt\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred = gb.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "rmse_test = mse_test ** (1 / 2)\n",
    "print(f\"GradientBoostingRegressor RMSE: {rmse_test:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Boosting\n",
    "\n",
    "_Stochastic gradient boosting_ or SGB is a variant of gradient boosting that introduces randomness into the training process, much like random forests.\n",
    "\n",
    "In SGB, each learner (tree) is trained on a random subset of the training data. The `subsample` hyperparameter controls the size of the subset. The `max_features` hyperparameter controls the number of features to consider when splitting a node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor RMSE: 52.07\n"
     ]
    }
   ],
   "source": [
    "sgbr = GradientBoostingRegressor(\n",
    "    learning_rate=0.1,\n",
    "    max_depth=4,\n",
    "    subsample=0.9,\n",
    "    max_features=0.75,\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "X = bikes_df.drop(\"cnt\", axis=1).values\n",
    "y = bikes_df[\"cnt\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "sgbr.fit(X_train, y_train)\n",
    "y_pred = sgbr.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "rmse_test = mse_test ** (1 / 2)\n",
    "print(f\"SGDRegressor RMSE: {rmse_test:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "**Articles**\n",
    "- <https://en.wikipedia.org/wiki/Hyperparameter_optimization>\n",
    "- <https://wandb.ai/site/articles/intro-to-mlops-hyperparameter-tuning>\n",
    "- <https://scikit-learn.org/stable/modules/grid_search.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV\n",
    "\n",
    "_Grid search cross-validation_ (GridSearchCV) is a method of hyperparameter tuning that uses a grid (matrix) of hyperparameter values to train and evaluate a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.73\n"
     ]
    }
   ],
   "source": [
    "X = liver_df.drop(\"Patient\", axis=1).values\n",
    "y = liver_df[\"Patient\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "params_dt = {\n",
    "    \"max_depth\": [2, 3, 4],\n",
    "    \"min_samples_leaf\": [0.12, 0.14, 0.16, 0.18],\n",
    "}\n",
    "grid_dt = GridSearchCV(\n",
    "    estimator=dt,\n",
    "    param_grid=params_dt,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "grid_dt.fit(X_train, y_train)\n",
    "best_model = grid_dt.best_estimator_\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class=\"ovo\")\n",
    "print(f\"ROC AUC: {test_roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 84.54\n"
     ]
    }
   ],
   "source": [
    "X = bikes_df.drop(\"cnt\", axis=1).values\n",
    "y = bikes_df[\"cnt\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "params_rf = {\n",
    "    \"n_estimators\": [100, 350, 500],\n",
    "    \"max_features\": [\"log2\", \"auto\", \"sqrt\"],\n",
    "    \"min_samples_leaf\": [2, 10, 30],\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=25, random_state=42)\n",
    "grid_rf = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=params_rf,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_rf.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "rmse_test = mean_squared_error(y_test, y_pred) ** (1 / 2)\n",
    "print(f\"RMSE: {rmse_test:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
