{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Importing Data in Python](https://www.datacamp.com/completed/statement-of-accomplishment/course/987436db924b8f6ab6a975f730c5a359f71e4363)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adamelliotfields/datacamp/blob/main/notebooks/courses/importing_data_in_python/notebook.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "* [Web Scraping](#Web-Scraping-üîù)\n",
    "* [APIs](#APIs-üîù)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping üîù\n",
    "\n",
    "Beautiful Soup is a Python library for parsing structured HTML and XML data. It was created in 2004 (older than jQuery) by Leonard Richardson who maintains it to this day. The name comes from \"tag soup\", a term coined by Ken Holman to describe structurally or syntactically incorrect XML.\n",
    "\n",
    "To get the HTML data, Python's standard library includes the `urllib` module. For more advanced functionality, the `requests` library is the most popular choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  alcohol  quality\n",
      "0            7.4              0.70         0.00             1.9      0.076                 11.0                  34.0   0.9978  3.51       0.56      9.4        5\n",
      "1            7.8              0.88         0.00             2.6      0.098                 25.0                  67.0   0.9968  3.20       0.68      9.8        5\n",
      "2            7.8              0.76         0.04             2.3      0.092                 15.0                  54.0   0.9970  3.26       0.65      9.8        5\n",
      "3           11.2              0.28         0.56             1.9      0.075                 17.0                  60.0   0.9980  3.16       0.58      9.8        6\n",
      "4            7.4              0.70         0.00             1.9      0.076                 11.0                  34.0   0.9978  3.51       0.56      9.4        5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "url = \"https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv\"\n",
    "filename = \"winequality-red.csv\"\n",
    "\n",
    "# only retrieve if it doesn't exist\n",
    "try:\n",
    "    file = open(filename)\n",
    "    file.close()\n",
    "except FileNotFoundError:\n",
    "    urlretrieve(url, filename)\n",
    "\n",
    "# can also pass the url to Pandas directly\n",
    "df = pd.read_csv(filename, sep=\";\")\n",
    "pd.set_option(\"display.width\", sys.maxsize)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'http.client.HTTPResponse'>\n",
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "\n",
    "url = \"https://campus.datacamp.com/courses/1606/4135?ex=2\"\n",
    "request = Request(url)\n",
    "response = urlopen(request)\n",
    "html = response.read()\n",
    "\n",
    "print(type(response))\n",
    "print(type(html))\n",
    "\n",
    "response.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://www.datacamp.com/teach/documentation\"\n",
    "r = requests.get(url)\n",
    "text = r.text\n",
    "\n",
    "print(type(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pics.html\n",
      "pics.html\n",
      "http://www.washingtonpost.com/wp-srv/business/longterm/microsoft/stories/1998/raymond120398.htm\n",
      "images/df20000406.jpg\n",
      "http://neopythonic.blogspot.com/2016/04/kings-day-speech.html\n",
      "http://www.python.org\n",
      "Resume.html\n",
      "Publications.html\n",
      "bio.html\n",
      "http://legacy.python.org/doc/essays/\n",
      "http://legacy.python.org/doc/essays/ppt/\n",
      "interviews.html\n",
      "pics.html\n",
      "http://neopythonic.blogspot.com\n",
      "http://www.artima.com/weblogs/index.jsp?blogger=12088\n",
      "https://twitter.com/gvanrossum\n",
      "Resume.html\n",
      "guido.au\n",
      "http://legacy.python.org/doc/essays/\n",
      "images/license.jpg\n",
      "http://www.cnpbagwell.com/audio-faq\n",
      "http://sox.sourceforge.net/\n",
      "images/internetdog.gif\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.python.org/~guido\"\n",
    "r = requests.get(url)\n",
    "html_doc = r.text\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# format HTML\n",
    "pretty_soup = soup.prettify()\n",
    "\n",
    "# get the title tag\n",
    "guido_title = soup.title\n",
    "\n",
    "# get all the text on the page\n",
    "guido_text = soup.get_text()\n",
    "\n",
    "# get all the hyperlinks on the page\n",
    "a_tags = soup.find_all(\"a\")\n",
    "\n",
    "# loop over tags\n",
    "for tag in a_tags:\n",
    "    print(tag.get(\"href\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APIs üîù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Title\":\"The Social Network\",\"Year\":\"2010\",\"Rated\":\"PG-13\",\"Released\":\"01 Oct 2010\",\"Runtime\":\"120 min\",\"Genre\":\"Biography, Drama\",\"Director\":\"David Fincher\",\"Writer\":\"Aaron Sorkin, Ben Mezrich\",\"Actors\":\"Jesse Eisenberg, Andrew Garfield, Justin Timberlake\",\"Plot\":\"As Harvard student Mark Zuckerberg creates the social networking site that would become known as Facebook, he is sued by the twins who claimed he stole their idea and by the co-founder who was later squeezed out of the business.\",\"Language\":\"English, French\",\"Country\":\"United States\",\"Awards\":\"Won 3 Oscars. 173 wins & 186 nominations total\",\"Poster\":\"https://m.media-amazon.com/images/M/MV5BOGUyZDUxZjEtMmIzMC00MzlmLTg4MGItZWJmMzBhZjE0Mjc1XkEyXkFqcGdeQXVyMTMxODk2OTU@._V1_SX300.jpg\",\"Ratings\":[{\"Source\":\"Internet Movie Database\",\"Value\":\"7.8/10\"},{\"Source\":\"Rotten Tomatoes\",\"Value\":\"96%\"},{\"Source\":\"Metacritic\",\"Value\":\"95/100\"}],\"Metascore\":\"95\",\"imdbRating\":\"7.8\",\"imdbVotes\":\"735,077\",\"imdbID\":\"tt1285016\",\"Type\":\"movie\",\"DVD\":\"05 Jun 2012\",\"BoxOffice\":\"$96,962,694\",\"Production\":\"N/A\",\"Website\":\"N/A\",\"Response\":\"True\"}\n",
      "The Social Network\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# this api key is from the course\n",
    "url = \"https://www.omdbapi.com?t=the+social+network&apikey=72bc447a\"\n",
    "r = requests.get(url)\n",
    "j = r.json()\n",
    "\n",
    "print(r.text)\n",
    "print(j[\"Title\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 2017, the world pizza market was US$128 billion, and in the US it was $44 billion spread over 76,000 pizzerias.  Overall, 13% of the U.S. population aged two years and over consumed pizza on any given day.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://en.wikipedia.org/w/api.php?action=query&prop=extracts&format=json&exintro=&titles=pizza\"\n",
    "r = requests.get(url)\n",
    "j = r.json()\n",
    "\n",
    "# we want the text within the last \"p\" tag\n",
    "pizza_extract = j[\"query\"][\"pages\"][\"24768\"][\"extract\"]\n",
    "soup = BeautifulSoup(pizza_extract)\n",
    "text = soup.find_all(\"p\")[-1].get_text()\n",
    "\n",
    "print(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datacamp-kYionb3o-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
