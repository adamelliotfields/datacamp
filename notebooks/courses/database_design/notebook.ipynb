{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Database Design](https://www.datacamp.com/completed/statement-of-accomplishment/course/498342bb908b69d02b6266ed83aa243199c708da)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adamelliotfields/datacamp/blob/main/notebooks/courses/database_design/notebook.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLTP and OLAP\n",
    "  * OLTP: Online Transaction Processing\n",
    "  * OLAP: Online Analytical Processing\n",
    "\n",
    "\"Online\" meaning that the data is processed in real time, as soon as it is entered into the system. This is in contrast to batch processing, where data is entered into the system in batches, and then processed at a later time.\n",
    "\n",
    "In the context of database design, knowing how the data is going to be used is critical in determining how to store and organize the data.\n",
    "\n",
    "A blog with a large number of readers and multiple authors writing and editing posts daily would be an example of a system that is designed for OLTP and optimized for frequent changes to the data.\n",
    "\n",
    "A data warehouse that stores all the subscriber information, user analytics, site metrics, and logs would be an example of a system that is designed for OLAP. The data warehouse would be optimized for large, complex queries across multiple dimensions.\n",
    "\n",
    "OLTP systems are oriented around the application, while OLAP systems are oriented around the data being analyzed.\n",
    "\n",
    "Note that OLTP and OLAP systems are not mutually exclusive! In fact, the structured data from an OLTP database could be pulled into an OLAP data warehouse for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structuring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structured\n",
    "\n",
    "Structured data follows a _schema_ that defines the data types and their relationships. Examples of structured data include spreadsheets (e.g., CSV) and relational databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semi-structured\n",
    "\n",
    "Semi-structured data does not follow a predefined schema, rather it is _self-describing_. Examples of semi-structured data include JSON, XML, and NoSQL databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unstructured\n",
    "\n",
    "Unstructured data has no structure at all. Examples include documents, images, and logs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Warehouse vs Data Lake\n",
    "\n",
    "_Data Warehouses_ pull data from multiple sources and are optimized for reads on massive (petabyte+) datasets. AWS Redshift and GCP BigQuery are two of the most popular cloud data warehousing solutions. Snowflake is a cloud-agnostic/multi-cloud data-warehouse-as-a-service. Warehouses typically store structured and semi-structured data.\n",
    "\n",
    "_Data Lakes_ store raw data in its native format. They are often used as a staging area for data warehouses. The data can be processed and \"loaded\" into the warehouse. The underlying storage is typically something like AWS S3 or GCP Cloud Storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL vs ELT\n",
    "  * ETL: Extract, Transform, Load\n",
    "  * ELT: Extract, Load, Transform\n",
    "\n",
    "In _ETL_, data is transformed **before** being loaded into storage. In contrast, _ELT_ is loaded into storage **before** being transformed. Typically you'll see ELT when working with data lakes.\n",
    "\n",
    "_Extracting_ data from a source system is the first step in both ETL and ELT. This could be the result of a SQL query, an API request, or even a website scraping job.\n",
    "\n",
    "_Loading_ simply means writing the data to disk. This could be a database or a cloud storage bucket.\n",
    "\n",
    "_Transforming_ data is the process of converting it from one format to another. This could be as simple as converting a CSV file to a SQL table, or as complex as a multi-step data pipeline that cleans, aggregates, and joins multiple datasets.\n",
    "\n",
    "In ETL, you might pull data from a traditional database or API, vectorize it, and then store it in a specialized database for machine learning.\n",
    "\n",
    "In ELT, large amounts of data are essentially dumped into storage buckets. This could be raw sensor data from IoT devices or logs from web services. The data can be transformed when it is needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database Models and Schemas\n",
    "\n",
    "_Models_ are high-level database specifications. For example, the _relational model_ specifies that data is stored in tables with rows and columns. In the context of database design, \"model\" is not the same as the \"model\" from MVC (a design pattern for structuring application code).\n",
    "\n",
    "_Schemas_ are the specific implementation of a model. A schema defines the actual structure of the database, including the data types and relationships. Don't confuse this with Postgres' schemas, which are used to organize database objects like tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Modeling\n",
    "\n",
    "There are 3 levels to data modeling:\n",
    "  * Conceptual: high-level overview\n",
    "  * Logical: more detail\n",
    "  * Physical: specific implementation\n",
    "\n",
    "The conceptual level is the most abstract. It aims to visualize the entities and their relationships using an _Entity-Relationship Diagram_ (ERD). The logical level adds more detail, including data types and cardinality (e.g., 1:1, 1:N, N:M). The physical level would include database-specific implementation details.\n",
    "\n",
    "The most common ERD notation is [Barker's](https://en.wikipedia.org/wiki/Barker%27s_notation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensional Modeling\n",
    "\n",
    "_Dimensional modeling_ is a technique for designing databases that are optimized for OLAP queries often used in data warehouses. The data is organized into _facts_ and _dimensions_.\n",
    "\n",
    "Fact tables contain the measurements, metrics, or \"facts\" of a business process. They are related to dimension tables by foreign keys. Dimension tables contain the \"dimensions\" of a business process.\n",
    "\n",
    "A fact table for \"songs\" might have columns for `title` and `duration` with foreign keys `album_id`, `artist_id`, and `genre_id`. Records in dimension tables won't change as often as records in fact tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schemas and Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Star and Snowflake Schemas\n",
    "\n",
    "The _Star_ schema is the simplest dimensional model. In fact, some use the term \"star schema\" and \"dimensional model\" interchangeably. The fact table is at the center of the star, with dimension tables radiating out from it. Dimension tables have a one-to-many relationship with the fact table: one record in the dimension table can be related to many records in the fact table (e.g., one artist can have many songs).\n",
    "\n",
    "The _Snowflake_ schema is an extension of the Star schema that adds additional dimensions to reduce redundancy in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "_Normalization_ is the process of organizing data in a database to reduce redundancy. It also improves data integrity by reducing the likelihood of inconsistent data. For example, if a customer changes their address, you only have to update one record in the `customers` table instead of multiple records in the `orders` table.\n",
    "\n",
    "Normalization is classified into \"normal forms\". Each normal form builds on the previous one, with 3NF being the most common."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1NF\n",
    "\n",
    "_1NF_ is the most basic form of normalization. It requires that each column in a table be _atomic_ (i.e., no repeating groups or arrays). For example, a `customers` table should not have a `phone_numbers` column that contains multiple phone numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2NF\n",
    "\n",
    "If a table has a single primary key column (e.g., a UUID) and it is already 1NF, then it is automatically _2NF_. If a table has a composite primary key (multiple columns), then each non-key column must be fully dependent on the entire primary key (all primary keys combined for that record must uniquely identify it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3NF\n",
    "\n",
    "To be _3NF_, a table must already be 2NF and every non-key column most be independent of every other non-key column (i.e., no transitive dependencies amongst columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Views\n",
    "\n",
    "A _view_ is the result set of a stored query that itself can be queried as if it were a \"physical\" table in the database. Views are dynamically generated when they are queried.\n",
    "\n",
    "Views allow you to properly normalize your database while providing simpler interfaces for querying. This is known as _denormalization_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Materialized Views\n",
    "\n",
    "Views can be _materialized_, in that they are actually persisted to disk. This is useful for views that can take a long time to generate (i.e., query takes hours). Materialized views would be refreshed either manually or on a schedule. For example, you might schedule a cron job to update a materialized view overnight while website traffic is low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Administration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Control\n",
    "\n",
    "Database administraters can _grant_ or _revoke_ privileges to individual users or groups of users by way of _roles_. Groups themselves are actually just roles comprised of other roles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning\n",
    "\n",
    "_Partitioning_ is the process of splitting a large table into smaller tables. Partitioning can be _vertical_ or _horizontal_.\n",
    "\n",
    "Splitting on columns is vertical; splitting on rows is horizontal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datacamp-kYionb3o-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
